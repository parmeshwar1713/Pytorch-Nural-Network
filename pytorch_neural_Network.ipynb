{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40e540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d0531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417c305bc57b4729865407e8eaebf6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a081c82c80cd43bcb48413cfb6865991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cba1f4e5007424280642b5f217dcfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d36be836a8446586fc0092e9b35e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c4e054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d45c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad024d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1653c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67c7fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "725f9857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303911  [    0/60000]\n",
      "loss: 2.286771  [ 6400/60000]\n",
      "loss: 2.267155  [12800/60000]\n",
      "loss: 2.269669  [19200/60000]\n",
      "loss: 2.243989  [25600/60000]\n",
      "loss: 2.221242  [32000/60000]\n",
      "loss: 2.228081  [38400/60000]\n",
      "loss: 2.194650  [44800/60000]\n",
      "loss: 2.189980  [51200/60000]\n",
      "loss: 2.171153  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 2.158740 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.163016  [    0/60000]\n",
      "loss: 2.154173  [ 6400/60000]\n",
      "loss: 2.094731  [12800/60000]\n",
      "loss: 2.126308  [19200/60000]\n",
      "loss: 2.068119  [25600/60000]\n",
      "loss: 2.001227  [32000/60000]\n",
      "loss: 2.034321  [38400/60000]\n",
      "loss: 1.951879  [44800/60000]\n",
      "loss: 1.949926  [51200/60000]\n",
      "loss: 1.893451  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 1.889616 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.908546  [    0/60000]\n",
      "loss: 1.887289  [ 6400/60000]\n",
      "loss: 1.767754  [12800/60000]\n",
      "loss: 1.827780  [19200/60000]\n",
      "loss: 1.713734  [25600/60000]\n",
      "loss: 1.649969  [32000/60000]\n",
      "loss: 1.678424  [38400/60000]\n",
      "loss: 1.577400  [44800/60000]\n",
      "loss: 1.592079  [51200/60000]\n",
      "loss: 1.501680  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.518984 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.572264  [    0/60000]\n",
      "loss: 1.547176  [ 6400/60000]\n",
      "loss: 1.393341  [12800/60000]\n",
      "loss: 1.482796  [19200/60000]\n",
      "loss: 1.366876  [25600/60000]\n",
      "loss: 1.346381  [32000/60000]\n",
      "loss: 1.366011  [38400/60000]\n",
      "loss: 1.289722  [44800/60000]\n",
      "loss: 1.313484  [51200/60000]\n",
      "loss: 1.229652  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.252987 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.318410  [    0/60000]\n",
      "loss: 1.309073  [ 6400/60000]\n",
      "loss: 1.140396  [12800/60000]\n",
      "loss: 1.260651  [19200/60000]\n",
      "loss: 1.143317  [25600/60000]\n",
      "loss: 1.150048  [32000/60000]\n",
      "loss: 1.174576  [38400/60000]\n",
      "loss: 1.111431  [44800/60000]\n",
      "loss: 1.138903  [51200/60000]\n",
      "loss: 1.071344  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.088872 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.148144  [    0/60000]\n",
      "loss: 1.160361  [ 6400/60000]\n",
      "loss: 0.976327  [12800/60000]\n",
      "loss: 1.123106  [19200/60000]\n",
      "loss: 1.006182  [25600/60000]\n",
      "loss: 1.017922  [32000/60000]\n",
      "loss: 1.055342  [38400/60000]\n",
      "loss: 0.997926  [44800/60000]\n",
      "loss: 1.024287  [51200/60000]\n",
      "loss: 0.972111  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.982873 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.029208  [    0/60000]\n",
      "loss: 1.064002  [ 6400/60000]\n",
      "loss: 0.864689  [12800/60000]\n",
      "loss: 1.031988  [19200/60000]\n",
      "loss: 0.918111  [25600/60000]\n",
      "loss: 0.924446  [32000/60000]\n",
      "loss: 0.976738  [38400/60000]\n",
      "loss: 0.924457  [44800/60000]\n",
      "loss: 0.944607  [51200/60000]\n",
      "loss: 0.904920  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.910358 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.941639  [    0/60000]\n",
      "loss: 0.997131  [ 6400/60000]\n",
      "loss: 0.784762  [12800/60000]\n",
      "loss: 0.967302  [19200/60000]\n",
      "loss: 0.857581  [25600/60000]\n",
      "loss: 0.855444  [32000/60000]\n",
      "loss: 0.920800  [38400/60000]\n",
      "loss: 0.875611  [44800/60000]\n",
      "loss: 0.887191  [51200/60000]\n",
      "loss: 0.856073  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.857960 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.874279  [    0/60000]\n",
      "loss: 0.947264  [ 6400/60000]\n",
      "loss: 0.724733  [12800/60000]\n",
      "loss: 0.919030  [19200/60000]\n",
      "loss: 0.812989  [25600/60000]\n",
      "loss: 0.803238  [32000/60000]\n",
      "loss: 0.878521  [38400/60000]\n",
      "loss: 0.841904  [44800/60000]\n",
      "loss: 0.844268  [51200/60000]\n",
      "loss: 0.818343  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.818214 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.820672  [    0/60000]\n",
      "loss: 0.907302  [ 6400/60000]\n",
      "loss: 0.677805  [12800/60000]\n",
      "loss: 0.881599  [19200/60000]\n",
      "loss: 0.778417  [25600/60000]\n",
      "loss: 0.762990  [32000/60000]\n",
      "loss: 0.844544  [38400/60000]\n",
      "loss: 0.817192  [44800/60000]\n",
      "loss: 0.811151  [51200/60000]\n",
      "loss: 0.787641  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.786640 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.776551  [    0/60000]\n",
      "loss: 0.873215  [ 6400/60000]\n",
      "loss: 0.639753  [12800/60000]\n",
      "loss: 0.851517  [19200/60000]\n",
      "loss: 0.750242  [25600/60000]\n",
      "loss: 0.731290  [32000/60000]\n",
      "loss: 0.815930  [38400/60000]\n",
      "loss: 0.797835  [44800/60000]\n",
      "loss: 0.784871  [51200/60000]\n",
      "loss: 0.761700  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.760484 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.739124  [    0/60000]\n",
      "loss: 0.843008  [ 6400/60000]\n",
      "loss: 0.607868  [12800/60000]\n",
      "loss: 0.826646  [19200/60000]\n",
      "loss: 0.726356  [25600/60000]\n",
      "loss: 0.705642  [32000/60000]\n",
      "loss: 0.790807  [38400/60000]\n",
      "loss: 0.781739  [44800/60000]\n",
      "loss: 0.763082  [51200/60000]\n",
      "loss: 0.738888  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.737999 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.706630  [    0/60000]\n",
      "loss: 0.815645  [ 6400/60000]\n",
      "loss: 0.580586  [12800/60000]\n",
      "loss: 0.805684  [19200/60000]\n",
      "loss: 0.705634  [25600/60000]\n",
      "loss: 0.684243  [32000/60000]\n",
      "loss: 0.768149  [38400/60000]\n",
      "loss: 0.767612  [44800/60000]\n",
      "loss: 0.744517  [51200/60000]\n",
      "loss: 0.718509  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.718157 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.677967  [    0/60000]\n",
      "loss: 0.790640  [ 6400/60000]\n",
      "loss: 0.556886  [12800/60000]\n",
      "loss: 0.787495  [19200/60000]\n",
      "loss: 0.687611  [25600/60000]\n",
      "loss: 0.666132  [32000/60000]\n",
      "loss: 0.747348  [38400/60000]\n",
      "loss: 0.754706  [44800/60000]\n",
      "loss: 0.728481  [51200/60000]\n",
      "loss: 0.700025  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.700295 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.652443  [    0/60000]\n",
      "loss: 0.767560  [ 6400/60000]\n",
      "loss: 0.536073  [12800/60000]\n",
      "loss: 0.771399  [19200/60000]\n",
      "loss: 0.671787  [25600/60000]\n",
      "loss: 0.650496  [32000/60000]\n",
      "loss: 0.728126  [38400/60000]\n",
      "loss: 0.742730  [44800/60000]\n",
      "loss: 0.714431  [51200/60000]\n",
      "loss: 0.683138  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.684009 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.629603  [    0/60000]\n",
      "loss: 0.746210  [ 6400/60000]\n",
      "loss: 0.517527  [12800/60000]\n",
      "loss: 0.756798  [19200/60000]\n",
      "loss: 0.657872  [25600/60000]\n",
      "loss: 0.636782  [32000/60000]\n",
      "loss: 0.710238  [38400/60000]\n",
      "loss: 0.731714  [44800/60000]\n",
      "loss: 0.702088  [51200/60000]\n",
      "loss: 0.667476  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.669083 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.609027  [    0/60000]\n",
      "loss: 0.726590  [ 6400/60000]\n",
      "loss: 0.500986  [12800/60000]\n",
      "loss: 0.743434  [19200/60000]\n",
      "loss: 0.645675  [25600/60000]\n",
      "loss: 0.624824  [32000/60000]\n",
      "loss: 0.693491  [38400/60000]\n",
      "loss: 0.721761  [44800/60000]\n",
      "loss: 0.691283  [51200/60000]\n",
      "loss: 0.652990  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.655363 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.590474  [    0/60000]\n",
      "loss: 0.708440  [ 6400/60000]\n",
      "loss: 0.486098  [12800/60000]\n",
      "loss: 0.731086  [19200/60000]\n",
      "loss: 0.634870  [25600/60000]\n",
      "loss: 0.614351  [32000/60000]\n",
      "loss: 0.677906  [38400/60000]\n",
      "loss: 0.712837  [44800/60000]\n",
      "loss: 0.681873  [51200/60000]\n",
      "loss: 0.639510  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.642730 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.573681  [    0/60000]\n",
      "loss: 0.691711  [ 6400/60000]\n",
      "loss: 0.472599  [12800/60000]\n",
      "loss: 0.719610  [19200/60000]\n",
      "loss: 0.625236  [25600/60000]\n",
      "loss: 0.605140  [32000/60000]\n",
      "loss: 0.663397  [38400/60000]\n",
      "loss: 0.704947  [44800/60000]\n",
      "loss: 0.673708  [51200/60000]\n",
      "loss: 0.626925  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.631100 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.558417  [    0/60000]\n",
      "loss: 0.676307  [ 6400/60000]\n",
      "loss: 0.460341  [12800/60000]\n",
      "loss: 0.708888  [19200/60000]\n",
      "loss: 0.616579  [25600/60000]\n",
      "loss: 0.596967  [32000/60000]\n",
      "loss: 0.649947  [38400/60000]\n",
      "loss: 0.698069  [44800/60000]\n",
      "loss: 0.666668  [51200/60000]\n",
      "loss: 0.615178  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.620395 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.544461  [    0/60000]\n",
      "loss: 0.662091  [ 6400/60000]\n",
      "loss: 0.449174  [12800/60000]\n",
      "loss: 0.698832  [19200/60000]\n",
      "loss: 0.608774  [25600/60000]\n",
      "loss: 0.589557  [32000/60000]\n",
      "loss: 0.637402  [38400/60000]\n",
      "loss: 0.692122  [44800/60000]\n",
      "loss: 0.660576  [51200/60000]\n",
      "loss: 0.604148  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.610542 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.531649  [    0/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.648978  [ 6400/60000]\n",
      "loss: 0.438912  [12800/60000]\n",
      "loss: 0.689373  [19200/60000]\n",
      "loss: 0.601630  [25600/60000]\n",
      "loss: 0.582825  [32000/60000]\n",
      "loss: 0.625785  [38400/60000]\n",
      "loss: 0.687065  [44800/60000]\n",
      "loss: 0.655425  [51200/60000]\n",
      "loss: 0.593810  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.601479 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.519870  [    0/60000]\n",
      "loss: 0.636926  [ 6400/60000]\n",
      "loss: 0.429492  [12800/60000]\n",
      "loss: 0.680418  [19200/60000]\n",
      "loss: 0.594908  [25600/60000]\n",
      "loss: 0.576734  [32000/60000]\n",
      "loss: 0.615031  [38400/60000]\n",
      "loss: 0.682755  [44800/60000]\n",
      "loss: 0.651075  [51200/60000]\n",
      "loss: 0.584136  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.593138 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.508971  [    0/60000]\n",
      "loss: 0.625784  [ 6400/60000]\n",
      "loss: 0.420845  [12800/60000]\n",
      "loss: 0.671937  [19200/60000]\n",
      "loss: 0.588561  [25600/60000]\n",
      "loss: 0.571065  [32000/60000]\n",
      "loss: 0.605094  [38400/60000]\n",
      "loss: 0.679175  [44800/60000]\n",
      "loss: 0.647368  [51200/60000]\n",
      "loss: 0.574954  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.585451 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.498832  [    0/60000]\n",
      "loss: 0.615462  [ 6400/60000]\n",
      "loss: 0.412883  [12800/60000]\n",
      "loss: 0.663898  [19200/60000]\n",
      "loss: 0.582433  [25600/60000]\n",
      "loss: 0.565799  [32000/60000]\n",
      "loss: 0.595915  [38400/60000]\n",
      "loss: 0.676338  [44800/60000]\n",
      "loss: 0.644197  [51200/60000]\n",
      "loss: 0.566144  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.578347 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.489415  [    0/60000]\n",
      "loss: 0.605883  [ 6400/60000]\n",
      "loss: 0.405490  [12800/60000]\n",
      "loss: 0.656239  [19200/60000]\n",
      "loss: 0.576495  [25600/60000]\n",
      "loss: 0.560863  [32000/60000]\n",
      "loss: 0.587393  [38400/60000]\n",
      "loss: 0.674120  [44800/60000]\n",
      "loss: 0.641425  [51200/60000]\n",
      "loss: 0.557671  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.571771 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.480587  [    0/60000]\n",
      "loss: 0.596953  [ 6400/60000]\n",
      "loss: 0.398615  [12800/60000]\n",
      "loss: 0.648960  [19200/60000]\n",
      "loss: 0.570652  [25600/60000]\n",
      "loss: 0.556145  [32000/60000]\n",
      "loss: 0.579509  [38400/60000]\n",
      "loss: 0.672455  [44800/60000]\n",
      "loss: 0.639040  [51200/60000]\n",
      "loss: 0.549487  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.565675 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.472215  [    0/60000]\n",
      "loss: 0.588703  [ 6400/60000]\n",
      "loss: 0.392182  [12800/60000]\n",
      "loss: 0.642043  [19200/60000]\n",
      "loss: 0.564887  [25600/60000]\n",
      "loss: 0.551533  [32000/60000]\n",
      "loss: 0.572202  [38400/60000]\n",
      "loss: 0.671263  [44800/60000]\n",
      "loss: 0.636911  [51200/60000]\n",
      "loss: 0.541622  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.560012 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.464298  [    0/60000]\n",
      "loss: 0.581023  [ 6400/60000]\n",
      "loss: 0.386163  [12800/60000]\n",
      "loss: 0.635381  [19200/60000]\n",
      "loss: 0.559228  [25600/60000]\n",
      "loss: 0.547055  [32000/60000]\n",
      "loss: 0.565342  [38400/60000]\n",
      "loss: 0.670475  [44800/60000]\n",
      "loss: 0.634986  [51200/60000]\n",
      "loss: 0.534000  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.554737 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.456826  [    0/60000]\n",
      "loss: 0.573922  [ 6400/60000]\n",
      "loss: 0.380498  [12800/60000]\n",
      "loss: 0.629034  [19200/60000]\n",
      "loss: 0.553615  [25600/60000]\n",
      "loss: 0.542719  [32000/60000]\n",
      "loss: 0.558995  [38400/60000]\n",
      "loss: 0.669904  [44800/60000]\n",
      "loss: 0.633247  [51200/60000]\n",
      "loss: 0.526592  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.549807 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.449716  [    0/60000]\n",
      "loss: 0.567316  [ 6400/60000]\n",
      "loss: 0.375191  [12800/60000]\n",
      "loss: 0.622989  [19200/60000]\n",
      "loss: 0.548025  [25600/60000]\n",
      "loss: 0.538335  [32000/60000]\n",
      "loss: 0.553105  [38400/60000]\n",
      "loss: 0.669529  [44800/60000]\n",
      "loss: 0.631570  [51200/60000]\n",
      "loss: 0.519307  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.545184 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.442938  [    0/60000]\n",
      "loss: 0.561147  [ 6400/60000]\n",
      "loss: 0.370156  [12800/60000]\n",
      "loss: 0.617177  [19200/60000]\n",
      "loss: 0.542504  [25600/60000]\n",
      "loss: 0.534126  [32000/60000]\n",
      "loss: 0.547540  [38400/60000]\n",
      "loss: 0.669402  [44800/60000]\n",
      "loss: 0.629935  [51200/60000]\n",
      "loss: 0.512405  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.540864 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.436479  [    0/60000]\n",
      "loss: 0.555401  [ 6400/60000]\n",
      "loss: 0.365355  [12800/60000]\n",
      "loss: 0.611541  [19200/60000]\n",
      "loss: 0.537173  [25600/60000]\n",
      "loss: 0.530024  [32000/60000]\n",
      "loss: 0.542327  [38400/60000]\n",
      "loss: 0.669368  [44800/60000]\n",
      "loss: 0.628293  [51200/60000]\n",
      "loss: 0.505790  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.536797 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.430321  [    0/60000]\n",
      "loss: 0.550028  [ 6400/60000]\n",
      "loss: 0.360812  [12800/60000]\n",
      "loss: 0.606127  [19200/60000]\n",
      "loss: 0.531979  [25600/60000]\n",
      "loss: 0.526001  [32000/60000]\n",
      "loss: 0.537495  [38400/60000]\n",
      "loss: 0.669434  [44800/60000]\n",
      "loss: 0.626583  [51200/60000]\n",
      "loss: 0.499371  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.532965 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.424438  [    0/60000]\n",
      "loss: 0.545024  [ 6400/60000]\n",
      "loss: 0.356502  [12800/60000]\n",
      "loss: 0.600914  [19200/60000]\n",
      "loss: 0.526943  [25600/60000]\n",
      "loss: 0.522053  [32000/60000]\n",
      "loss: 0.532929  [38400/60000]\n",
      "loss: 0.669543  [44800/60000]\n",
      "loss: 0.624831  [51200/60000]\n",
      "loss: 0.493193  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.529355 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.418827  [    0/60000]\n",
      "loss: 0.540338  [ 6400/60000]\n",
      "loss: 0.352465  [12800/60000]\n",
      "loss: 0.595995  [19200/60000]\n",
      "loss: 0.521987  [25600/60000]\n",
      "loss: 0.518144  [32000/60000]\n",
      "loss: 0.528600  [38400/60000]\n",
      "loss: 0.669585  [44800/60000]\n",
      "loss: 0.622990  [51200/60000]\n",
      "loss: 0.487354  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.525952 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.413470  [    0/60000]\n",
      "loss: 0.535942  [ 6400/60000]\n",
      "loss: 0.348616  [12800/60000]\n",
      "loss: 0.591294  [19200/60000]\n",
      "loss: 0.517138  [25600/60000]\n",
      "loss: 0.514265  [32000/60000]\n",
      "loss: 0.524500  [38400/60000]\n",
      "loss: 0.669549  [44800/60000]\n",
      "loss: 0.621242  [51200/60000]\n",
      "loss: 0.481788  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.522733 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.408319  [    0/60000]\n",
      "loss: 0.531880  [ 6400/60000]\n",
      "loss: 0.344989  [12800/60000]\n",
      "loss: 0.586775  [19200/60000]\n",
      "loss: 0.512421  [25600/60000]\n",
      "loss: 0.510462  [32000/60000]\n",
      "loss: 0.520686  [38400/60000]\n",
      "loss: 0.669409  [44800/60000]\n",
      "loss: 0.619478  [51200/60000]\n",
      "loss: 0.476517  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.519689 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.403386  [    0/60000]\n",
      "loss: 0.528078  [ 6400/60000]\n",
      "loss: 0.341560  [12800/60000]\n",
      "loss: 0.582408  [19200/60000]\n",
      "loss: 0.507706  [25600/60000]\n",
      "loss: 0.506766  [32000/60000]\n",
      "loss: 0.517105  [38400/60000]\n",
      "loss: 0.669196  [44800/60000]\n",
      "loss: 0.617683  [51200/60000]\n",
      "loss: 0.471529  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.516799 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.398647  [    0/60000]\n",
      "loss: 0.524516  [ 6400/60000]\n",
      "loss: 0.338297  [12800/60000]\n",
      "loss: 0.578174  [19200/60000]\n",
      "loss: 0.503146  [25600/60000]\n",
      "loss: 0.503128  [32000/60000]\n",
      "loss: 0.513718  [38400/60000]\n",
      "loss: 0.668877  [44800/60000]\n",
      "loss: 0.615877  [51200/60000]\n",
      "loss: 0.466788  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.514047 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.394088  [    0/60000]\n",
      "loss: 0.521115  [ 6400/60000]\n",
      "loss: 0.335192  [12800/60000]\n",
      "loss: 0.574081  [19200/60000]\n",
      "loss: 0.498697  [25600/60000]\n",
      "loss: 0.499550  [32000/60000]\n",
      "loss: 0.510448  [38400/60000]\n",
      "loss: 0.668449  [44800/60000]\n",
      "loss: 0.614058  [51200/60000]\n",
      "loss: 0.462319  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.511421 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.389648  [    0/60000]\n",
      "loss: 0.517924  [ 6400/60000]\n",
      "loss: 0.332183  [12800/60000]\n",
      "loss: 0.570099  [19200/60000]\n",
      "loss: 0.494388  [25600/60000]\n",
      "loss: 0.496029  [32000/60000]\n",
      "loss: 0.507339  [38400/60000]\n",
      "loss: 0.667922  [44800/60000]\n",
      "loss: 0.612019  [51200/60000]\n",
      "loss: 0.458096  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.508912 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.385320  [    0/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.514878  [ 6400/60000]\n",
      "loss: 0.329351  [12800/60000]\n",
      "loss: 0.566278  [19200/60000]\n",
      "loss: 0.490141  [25600/60000]\n",
      "loss: 0.492624  [32000/60000]\n",
      "loss: 0.504452  [38400/60000]\n",
      "loss: 0.667314  [44800/60000]\n",
      "loss: 0.610030  [51200/60000]\n",
      "loss: 0.454149  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.506515 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.381130  [    0/60000]\n",
      "loss: 0.511952  [ 6400/60000]\n",
      "loss: 0.326634  [12800/60000]\n",
      "loss: 0.562596  [19200/60000]\n",
      "loss: 0.486071  [25600/60000]\n",
      "loss: 0.489343  [32000/60000]\n",
      "loss: 0.501641  [38400/60000]\n",
      "loss: 0.666538  [44800/60000]\n",
      "loss: 0.608049  [51200/60000]\n",
      "loss: 0.450366  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.504224 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.377006  [    0/60000]\n",
      "loss: 0.509192  [ 6400/60000]\n",
      "loss: 0.323984  [12800/60000]\n",
      "loss: 0.559064  [19200/60000]\n",
      "loss: 0.482193  [25600/60000]\n",
      "loss: 0.486171  [32000/60000]\n",
      "loss: 0.498951  [38400/60000]\n",
      "loss: 0.665613  [44800/60000]\n",
      "loss: 0.606119  [51200/60000]\n",
      "loss: 0.446753  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.502027 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.373001  [    0/60000]\n",
      "loss: 0.506602  [ 6400/60000]\n",
      "loss: 0.321451  [12800/60000]\n",
      "loss: 0.555644  [19200/60000]\n",
      "loss: 0.478440  [25600/60000]\n",
      "loss: 0.483073  [32000/60000]\n",
      "loss: 0.496386  [38400/60000]\n",
      "loss: 0.664594  [44800/60000]\n",
      "loss: 0.604095  [51200/60000]\n",
      "loss: 0.443291  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.499919 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.369093  [    0/60000]\n",
      "loss: 0.504126  [ 6400/60000]\n",
      "loss: 0.319029  [12800/60000]\n",
      "loss: 0.552330  [19200/60000]\n",
      "loss: 0.474782  [25600/60000]\n",
      "loss: 0.480087  [32000/60000]\n",
      "loss: 0.493943  [38400/60000]\n",
      "loss: 0.663471  [44800/60000]\n",
      "loss: 0.602018  [51200/60000]\n",
      "loss: 0.440041  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.497892 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.365241  [    0/60000]\n",
      "loss: 0.501734  [ 6400/60000]\n",
      "loss: 0.316700  [12800/60000]\n",
      "loss: 0.549208  [19200/60000]\n",
      "loss: 0.471275  [25600/60000]\n",
      "loss: 0.477186  [32000/60000]\n",
      "loss: 0.491503  [38400/60000]\n",
      "loss: 0.662251  [44800/60000]\n",
      "loss: 0.599906  [51200/60000]\n",
      "loss: 0.436962  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.495942 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.361496  [    0/60000]\n",
      "loss: 0.499453  [ 6400/60000]\n",
      "loss: 0.314454  [12800/60000]\n",
      "loss: 0.546284  [19200/60000]\n",
      "loss: 0.467884  [25600/60000]\n",
      "loss: 0.474397  [32000/60000]\n",
      "loss: 0.489117  [38400/60000]\n",
      "loss: 0.660977  [44800/60000]\n",
      "loss: 0.597846  [51200/60000]\n",
      "loss: 0.434065  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.494059 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.357921  [    0/60000]\n",
      "loss: 0.497255  [ 6400/60000]\n",
      "loss: 0.312308  [12800/60000]\n",
      "loss: 0.543457  [19200/60000]\n",
      "loss: 0.464509  [25600/60000]\n",
      "loss: 0.471729  [32000/60000]\n",
      "loss: 0.486802  [38400/60000]\n",
      "loss: 0.659563  [44800/60000]\n",
      "loss: 0.595779  [51200/60000]\n",
      "loss: 0.431287  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.492242 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb5d95de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198979bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27e6846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Coat\", Actual: \"Coat\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[10][0], test_data[10][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd653816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09fa947b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5686, 0.7451, 0.3804, 0.4275, 0.4118,\n",
       "          0.7333, 0.2980, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.2510, 0.6667, 0.6392, 0.8157, 0.9529, 0.9412, 0.8980,\n",
       "          0.6784, 0.6353, 0.6039, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529,\n",
       "          0.6196, 0.7686, 0.5843, 0.7490, 0.7804, 0.8745, 0.9529, 0.7294,\n",
       "          0.7490, 0.6667, 0.6078, 0.6353, 0.4941, 0.0863, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.4118, 0.6314,\n",
       "          0.5882, 0.5529, 0.5098, 0.7804, 0.9373, 0.8980, 0.8627, 0.7373,\n",
       "          0.9569, 0.5686, 0.5020, 0.5569, 0.5922, 0.6863, 0.0902, 0.0000,\n",
       "          0.0078, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5882, 0.5373,\n",
       "          0.5255, 0.5098, 0.5765, 0.4745, 0.9451, 1.0000, 0.4471, 0.9412,\n",
       "          0.6784, 0.5569, 0.5333, 0.5176, 0.5020, 0.6000, 0.4431, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.6157, 0.5059,\n",
       "          0.5725, 0.5843, 0.5373, 0.5529, 0.6941, 0.7843, 0.7843, 0.8118,\n",
       "          0.5255, 0.5686, 0.5569, 0.5490, 0.5176, 0.5059, 0.5490, 0.0118,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.6196, 0.5373,\n",
       "          0.6000, 0.5882, 0.4902, 0.6078, 0.7490, 0.6863, 0.5529, 0.6471,\n",
       "          0.6510, 0.6000, 0.5098, 0.5059, 0.5176, 0.5529, 0.5843, 0.0706,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3020, 0.6510, 0.6314,\n",
       "          0.5373, 0.5922, 0.6510, 0.7098, 0.8471, 0.7137, 0.6196, 0.8431,\n",
       "          0.7647, 0.6078, 0.6235, 0.6353, 0.6784, 0.5882, 0.5882, 0.2275,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4078, 0.6235, 0.6667,\n",
       "          0.5490, 0.5176, 0.7137, 0.7765, 0.8157, 0.6863, 0.5333, 0.6824,\n",
       "          0.6627, 0.5765, 0.6078, 0.4745, 0.7373, 0.6353, 0.5569, 0.3961,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4392, 0.6706, 0.8078,\n",
       "          0.7020, 0.5765, 0.6392, 0.6941, 0.7686, 0.7529, 0.5725, 0.7333,\n",
       "          0.6000, 0.5569, 0.5647, 0.5333, 0.9608, 0.7922, 0.5176, 0.5373,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.7098, 0.8588,\n",
       "          0.5725, 0.6157, 0.5020, 0.4745, 0.6863, 0.7686, 0.4078, 0.6157,\n",
       "          0.6196, 0.5922, 0.5490, 0.4039, 0.3490, 0.8667, 0.5529, 0.6000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6157, 0.6863, 0.8471,\n",
       "          0.2157, 0.6863, 0.6000, 0.5922, 0.7373, 0.8392, 0.4941, 0.8000,\n",
       "          0.6235, 0.5686, 0.5686, 0.4549, 0.2784, 0.8314, 0.6039, 0.6078,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.6392, 0.9098,\n",
       "          0.2510, 0.5412, 0.5569, 0.7137, 0.7647, 0.7843, 0.6196, 0.9059,\n",
       "          0.5725, 0.5098, 0.6314, 0.5176, 0.4118, 0.8824, 0.5725, 0.6157,\n",
       "          0.0392, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.7373, 0.6314, 0.8667,\n",
       "          0.2118, 0.5843, 0.6471, 0.5922, 0.6549, 0.7373, 0.6667, 0.7098,\n",
       "          0.6039, 0.5529, 0.5098, 0.5647, 0.3647, 0.8118, 0.6510, 0.5569,\n",
       "          0.1333, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.1647, 0.7137, 0.6471, 0.9255,\n",
       "          0.1137, 0.5725, 0.6667, 0.5529, 0.6510, 0.8157, 0.4863, 0.6353,\n",
       "          0.6784, 0.6039, 0.5176, 0.5490, 0.3804, 0.7608, 0.6000, 0.6314,\n",
       "          0.1843, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2275, 0.6863, 0.6706, 0.7490,\n",
       "          0.0196, 0.6784, 0.6353, 0.6039, 0.7098, 0.8118, 0.3922, 0.6314,\n",
       "          0.7020, 0.6078, 0.5725, 0.5843, 0.2980, 0.7529, 0.6353, 0.5882,\n",
       "          0.2431, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.3137, 0.7020, 0.6510, 0.6549,\n",
       "          0.0392, 0.7137, 0.5922, 0.6157, 0.6980, 0.7216, 0.6510, 0.8157,\n",
       "          0.6824, 0.5412, 0.5725, 0.5490, 0.2863, 0.7294, 0.6314, 0.6078,\n",
       "          0.2784, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.3922, 0.6471, 0.6706, 0.5412,\n",
       "          0.2000, 0.7608, 0.6157, 0.5216, 0.7333, 0.7686, 0.6510, 0.7765,\n",
       "          0.6392, 0.5059, 0.5569, 0.5255, 0.2863, 0.7490, 0.6039, 0.6078,\n",
       "          0.3098, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4275, 0.6196, 0.6863, 0.4627,\n",
       "          0.2863, 0.7020, 0.5725, 0.5843, 0.7176, 0.8118, 0.5529, 0.7216,\n",
       "          0.6706, 0.6000, 0.5373, 0.5765, 0.2863, 0.7647, 0.6157, 0.6039,\n",
       "          0.3333, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4275, 0.6392, 0.7020, 0.4784,\n",
       "          0.4549, 0.6941, 0.5647, 0.6471, 0.7137, 0.7451, 0.5765, 0.7020,\n",
       "          0.6353, 0.5725, 0.5216, 0.6000, 0.3804, 0.6314, 0.6196, 0.5882,\n",
       "          0.3725, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4196, 0.6196, 0.6549, 0.6392,\n",
       "          0.4118, 0.5373, 0.6314, 0.6392, 0.7961, 0.7804, 0.5843, 0.7098,\n",
       "          0.6549, 0.6314, 0.5765, 0.5765, 0.3882, 0.6510, 0.6157, 0.5529,\n",
       "          0.3882, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4275, 0.6039, 0.6510, 0.5686,\n",
       "          0.0000, 0.1333, 0.3294, 0.2471, 0.4196, 0.5843, 0.5176, 0.6000,\n",
       "          0.5059, 0.4863, 0.5843, 0.2196, 0.0000, 0.4471, 0.6235, 0.5529,\n",
       "          0.3804, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4235, 0.6039, 0.6627, 0.3333,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3647, 0.6157, 0.5569,\n",
       "          0.3882, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 0.6000, 0.6627, 0.3137,\n",
       "          0.0000, 0.0118, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.3137, 0.6078, 0.5647,\n",
       "          0.4118, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.6157, 0.6510, 0.2980,\n",
       "          0.0000, 0.0118, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.2627, 0.6353, 0.5529,\n",
       "          0.3922, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4863, 0.6000, 0.6353, 0.2000,\n",
       "          0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
       "          0.0000, 0.0039, 0.0000, 0.0196, 0.0000, 0.2275, 0.6549, 0.5725,\n",
       "          0.3412, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4784, 0.6471, 0.7098, 0.2118,\n",
       "          0.0000, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.2118, 0.6667, 0.5490,\n",
       "          0.2941, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.2941, 0.3608, 0.0118,\n",
       "          0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1137, 0.5686, 0.5373,\n",
       "          0.2314, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
